"""
ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - LightGBMã‚’ç”¨ã„ã¦3å€¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
"""

import os
import sys
import logging
from datetime import datetime
import pickle
import yaml
import pandas as pd
import numpy as np
from pathlib import Path
from dotenv import load_dotenv

import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# ç’°å¢ƒå¤‰æ•°ãƒ­ãƒ¼ãƒ‰
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ModelTrainer:
    """LightGBMãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path='config.yaml'):
        """åˆæœŸåŒ–"""
        self.config = self._load_config(config_path)
        self.model_path = Path(self.config['model']['model_path'])
        self.model_path.mkdir(parents=True, exist_ok=True)
        
        self.lgb_params = self.config['model']['lgb_params']
        self.model = None
    
    @staticmethod
    def _load_config(config_path):
        """YAMLã‚³ãƒ³ãƒ•ã‚£ã‚°ã‚’èª­ã¿è¾¼ã‚€"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def prepare_data(self, features):
        """
        ã™ãã«ä½¿ãˆã‚‹, ãƒ‡ãƒ¼ã‚¿ã‚’å­¦ç¿’/ãƒ†ã‚¹ãƒˆåˆ†å‰²ã«æº–å‚™
        
        Args:
            features (pd.DataFrame): ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿
        
        Returns:
            tuple: (X_train, X_test, y_train, y_test)
        """
        logger.info("ğŸ“Š Preparing training data...")
        
        # ç›®çš„å¤‰æ•°ã¨ç‰¹å¾´é‡ã‚’åˆ†é›¢
        y = features['target'].copy()
        X = features.drop(columns=['target', 'target_return']).copy()
        
        # NaNã‚’å‰Šé™¤
        valid_idx = ~y.isna()
        X = X[valid_idx]
        y = y[valid_idx]
        
        logger.info(f"   Total samples: {len(X)}")
        logger.info(f"   Class distribution: {y.value_counts().to_dict()}")
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãªã®ã§ï¼Œãƒ©ãƒ³ãƒ€ãƒ åˆ†å‰²ã§ã¯ãªãæ™‚é–“é †ã«åˆ†å‰²
        split_point = int(len(X) * (1 - self.config['model']['validation_split']))
        
        X_train = X.iloc[:split_point]
        X_test = X.iloc[split_point:]
        y_train = y.iloc[:split_point]
        y_test = y.iloc[split_point:]
        
        logger.info(f"   Train samples: {len(X_train)}")
        logger.info(f"   Test samples: {len(X_test)}")
        
        return X_train, X_test, y_train, y_test
    
    def train(self, X_train, y_train):
        """
        LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
        
        Args:
            X_train (pd.DataFrame): å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆç‰¹å¾´é‡ï¼‰
            y_train (pd.Series): å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ™ãƒ«ï¼‰
        """
        logger.info("ğŸ“ Training LightGBM model...")
        
        # LightGBMãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        train_data = lgb.Dataset(
            X_train,
            label=y_train,
            feature_name=list(X_train.columns)
        )
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°å‡ºåŠ›
        logger.info(f"   Model params: {self.lgb_params}")
        
        # å­¦ç¿’
        self.model = lgb.train(
            self.lgb_params,
            train_data,
            num_boost_round=self.config['model']['num_boosting_rounds']
        )
        
        logger.info("âœ… Model training complete")
    
    def evaluate(self, X_test, y_test):
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
        
        Args:
            X_test (pd.DataFrame): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆç‰¹å¾´é‡ï¼‰
            y_test (pd.Series): ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ™ãƒ«ï¼‰
        
        Returns:
            dict: è©•ä¾¡æŒ‡æ¨™
        """
        logger.info("ğŸ“ˆ Evaluating model...")
        
        if self.model is None:
            logger.error("Model not trained yet")
            return None
        
        # äºˆæ¸¬
        y_pred_proba = self.model.predict(X_test)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # ç²¾åº¦
        accuracy = accuracy_score(y_test, y_pred)
        logger.info(f"\n   Accuracy: {accuracy:.4f}")
        
        # ã‚¯ãƒ©ã‚¹ã”ã¨ã®è©•ä¾¡
        logger.info(f"\n   Classification Report:")
        report = classification_report(
            y_test, y_pred,
            target_names=['SHORT', 'LONG', 'NO_TRADE'],
            digits=4
        )
        logger.info(f"\n{report}")
        
        # æ··åŒè¡Œåˆ—
        logger.info(f"\n   Confusion Matrix:")
        cm = confusion_matrix(y_test, y_pred)
        logger.info(f"\n{cm}")
        
        # ç‰¹å¾´é‡ã®é‡è¦åº¦
        logger.info(f"\n   Top 10 Important Features:")
        importance = pd.DataFrame({
            'feature': X_test.columns,
            'importance': self.model.feature_importance()
        }).sort_values('importance', ascending=False).head(10)
        
        for idx, row in importance.iterrows():
            logger.info(f"      {row['feature']}: {row['importance']}")
        
        return {
            'accuracy': accuracy,
            'report': report,
            'confusion_matrix': cm.tolist(),
            'feature_importance': importance.to_dict()
        }
    
    def save_model(self, symbol='USDJPY'):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        if self.model is None:
            logger.error("No model to save")
            return None
        
        model_file = self.model_path / self.config['model']['model_filename']
        
        with open(model_file, 'wb') as f:
            pickle.dump(self.model, f)
        
        logger.info(f"ğŸ’¾ Model saved to {model_file}")
        return model_file
    
    @staticmethod
    def load_model(model_path):
        """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        if not os.path.exists(model_path):
            logger.error(f"Model file not found: {model_path}")
            return None
        
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
        
        logger.info(f"âœ… Model loaded from {model_path}")
        return model


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    import feature_engineer
    
    logger.info("=" * 50)
    logger.info("ğŸ“ Model Training Pipeline")
    logger.info("=" * 50)
    
    # ç‰¹å¾´é‡ã‚’å–å¾—
    engineer = feature_engineer.FeatureEngineer('config.yaml')
    features = engineer.get_latest_features('USDJPY')
    
    if features is not None:
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å™¨ã‚’åˆæœŸåŒ–
        trainer = ModelTrainer('config.yaml')
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
        X_train, X_test, y_train, y_test = trainer.prepare_data(features)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
        trainer.train(X_train, y_train)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
        trainer.evaluate(X_test, y_test)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
        trainer.save_model('USDJPY')
        
        logger.info("\nâœ… Training pipeline complete!")
        return trainer.model
    
    logger.error("âŒ Failed to train model")
    return None


if __name__ == '__main__':
    main()
